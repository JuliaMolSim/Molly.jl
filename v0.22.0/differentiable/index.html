<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Differentiable simulation · Molly.jl</title><meta name="title" content="Differentiable simulation · Molly.jl"/><meta property="og:title" content="Differentiable simulation · Molly.jl"/><meta property="twitter:title" content="Differentiable simulation · Molly.jl"/><meta name="description" content="Documentation for Molly.jl."/><meta property="og:description" content="Documentation for Molly.jl."/><meta property="twitter:description" content="Documentation for Molly.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="Molly.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">Molly.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../documentation/">Documentation</a></li><li class="is-active"><a class="tocitem" href>Differentiable simulation</a><ul class="internal"><li><a class="tocitem" href="#Pairwise-interactions"><span>Pairwise interactions</span></a></li><li><a class="tocitem" href="#Specific-interactions"><span>Specific interactions</span></a></li><li><a class="tocitem" href="#Neural-network-potentials"><span>Neural network potentials</span></a></li><li><a class="tocitem" href="#Biomolecular-force-fields"><span>Biomolecular force fields</span></a></li><li><a class="tocitem" href="#Reversible-simulation"><span>Reversible simulation</span></a></li><li><a class="tocitem" href="#Molecular-loss-functions"><span>Molecular loss functions</span></a></li><li><a class="tocitem" href="#Tips-and-tricks"><span>Tips and tricks</span></a></li></ul></li><li><a class="tocitem" href="../examples/">Examples</a></li><li><a class="tocitem" href="../exercises/">Exercises</a></li><li><a class="tocitem" href="../publications/">Publications</a></li><li><a class="tocitem" href="../related/">Related software</a></li><li><a class="tocitem" href="../development/">Development</a></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Differentiable simulation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Differentiable simulation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaMolSim/Molly.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaMolSim/Molly.jl/blob/master/docs/src/differentiable.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Differentiable-simulation-with-Molly"><a class="docs-heading-anchor" href="#Differentiable-simulation-with-Molly">Differentiable simulation with Molly</a><a id="Differentiable-simulation-with-Molly-1"></a><a class="docs-heading-anchor-permalink" href="#Differentiable-simulation-with-Molly" title="Permalink"></a></h1><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>There are still many rough edges when taking gradients through simulations. Please open an issue if you run into an error and remember the golden rule of AD: check your gradients against finite differencing if you want to make sure they are correct.</p></div></div><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>There are currently issues with running differentiable simulations on the GPU and on the CPU in certain cases. Hopefully these will be resolved soon.</p></div></div><p>In the last few years, the deep learning revolution has broadened to include the paradigm of <a href="https://en.wikipedia.org/wiki/Differentiable_programming">differentiable programming</a>. The concept of using automatic differentiation (AD) to obtain exact gradients through physical simulations has many interesting applications, including parameterising force fields and training neural networks to describe atomic potentials.</p><p>There are some projects that explore differentiable molecular simulations - see <a href="../related/#Related-software">Related software</a>. However Julia provides a strong suite of AD tools, with <a href="https://github.com/EnzymeAD/Enzyme.jl">Enzyme.jl</a> allowing source-to-source transformations for much of the language. With Molly you can use the power of Enzyme to obtain gradients through molecular simulations, even in the presence of complex interactions such as implicit solvation and stochasticity such as Langevin dynamics or the Andersen thermostat. Reverse and forward mode AD can be used on the CPU with multithreading and on the GPU; performance is typically within an order of magnitude of the primal run. Pairwise, specific and general interactions work, along with neighbor lists, and the same abstractions for running simulations are used as in the main package.</p><p>Differentiable simulation does not currently work with units and some components of the package. This is mentioned in the relevant docstrings. It is memory intensive on the GPU so using gradient checkpointing, e.g. with <a href="https://github.com/Argonne-National-Laboratory/Checkpointing.jl">Checkpointing.jl</a>, will likely be required for larger simulations.</p><h2 id="Pairwise-interactions"><a class="docs-heading-anchor" href="#Pairwise-interactions">Pairwise interactions</a><a id="Pairwise-interactions-1"></a><a class="docs-heading-anchor-permalink" href="#Pairwise-interactions" title="Permalink"></a></h2><p>First, we show how taking gradients through a simulation can be used to optimise an atom property in a <a href="https://en.wikipedia.org/wiki/Lennard-Jones_potential">Lennard-Jones</a> fluid. In this type of simulation each atom has a σ value that determines how close it likes to get to other atoms. We are going to find the σ value that results in a desired distance of each atom to its closest neighbor. First we need a function to obtain the mean distance of each atom to its closest neighbor:</p><pre><code class="language-julia hljs">using Molly, Statistics

function mean_min_separation(coords, boundary)
    min_seps = Float64[]
    for i in eachindex(coords)
        min_sq_sep = 100.0
        for j in eachindex(coords)
            if i != j
                sq_dist = sum(abs2, vector(coords[i], coords[j], boundary))
                min_sq_sep = min(sq_dist, min_sq_sep)
            end
        end
        push!(min_seps, sqrt(min_sq_sep))
    end
    return mean(min_seps)
end</code></pre><p>Now we can set up and run the simulation in a similar way to that described in the <a href="../documentation/#Molly-documentation">Molly documentation</a>. The difference is that we wrap the simulation in a <code>loss</code> function. This returns a single value that we want to obtain gradients with respect to, in this case the difference between the value of the above function at the end of the simulation and a target distance.</p><pre><code class="language-julia hljs">dist_true = 0.5
scale_σ_to_dist = 2 ^ (1 / 6)
σtrue = dist_true / scale_σ_to_dist

n_atoms = 50
n_steps = 500
atom_mass = 10.0
boundary = CubicBoundary(3.0)
temp = 1.0
simulator = VelocityVerlet(
    dt=0.02,
    coupling=RescaleThermostat(temp),
)
coords = place_atoms(n_atoms, boundary; min_dist=0.6)
velocities = [random_velocity(atom_mass, temp) for i in 1:n_atoms]
lj = LennardJones(cutoff=DistanceCutoff(1.5), use_neighbors=true)
pairwise_inters = (lj,)
neighbor_finder = DistanceNeighborFinder(
    eligible=trues(n_atoms, n_atoms),
    n_steps=10,
    dist_cutoff=1.8,
)

function loss(σ, coords, velocities, boundary, pairwise_inters,
              neighbor_finder, simulator, n_steps, n_atoms, atom_mass, dist_true)
    atoms = [Atom(i, 1, atom_mass, 0.0, σ, 0.2) for i in 1:n_atoms]

    sys = System(
        atoms=atoms,
        coords=coords,
        boundary=boundary,
        velocities=velocities,
        pairwise_inters=pairwise_inters,
        neighbor_finder=neighbor_finder,
        force_units=NoUnits,
        energy_units=NoUnits,
    )

    simulate!(sys, simulator, n_steps)
    mms_end = mean_min_separation(sys.coords, boundary)
    loss_val = abs(mms_end - dist_true)

    print(
        &quot;σ &quot;, round(σ; digits=3), &quot;  |  Mean min sep expected &quot;, round(σ * (2 ^ (1 / 6)); digits=3),
        &quot;  |  Mean min sep end &quot;, round(mms_end; digits=3), &quot;  |  Loss &quot;, round(loss_val; digits=3),
        &quot;  |  &quot;,
    )

    return loss_val
end</code></pre><p>We can obtain the gradient of <code>loss</code> with respect to the atom property <code>σ</code> using Enzyme.</p><pre><code class="language-julia hljs">using Enzyme

const_args = [
    Const(boundary), Const(pairwise_inters), Const(neighbor_finder),
    Const(simulator), Const(n_steps), Const(n_atoms),
    Const(atom_mass), Const(dist_true),
]

grad_enzyme = autodiff(
    set_runtime_activity(Reverse), loss, Active, Active(σtrue),
    Duplicated(coords, zero(coords)), Duplicated(velocities, zero(velocities)),
    const_args...,
)[1][1]</code></pre><p>This gradient can be used in a training loop to optimise <code>σ</code>, starting from an arbitrary value.</p><pre><code class="language-julia hljs">function train()
    σlearn = 0.60 / scale_σ_to_dist
    n_epochs = 15

    for epoch_n in 1:n_epochs
        print(&quot;Epoch &quot;, epoch_n, &quot;  |  &quot;)
        coords = place_atoms(n_atoms, boundary; min_dist=0.6)
        velocities = [random_velocity(atom_mass, temp) for i in 1:n_atoms]
        grad = autodiff(
            set_runtime_activity(Reverse), loss, Active, Active(σlearn),
            Duplicated(coords, zero(coords)), Duplicated(velocities, zero(velocities)),
            const_args...,
        )[1][1]
        println(&quot;Grad &quot;, round(grad; digits=3))
        σlearn -= grad * 1e-2
    end
end

train()</code></pre><pre><code class="nohighlight hljs">Epoch 1  |  σ 0.535  |  Mean min sep expected 0.6  |  Mean min sep end 0.59  |  Loss 0.09  |  Grad 1.495
Epoch 2  |  σ 0.52  |  Mean min sep expected 0.583  |  Mean min sep end 0.577  |  Loss 0.077  |  Grad 0.721
Epoch 3  |  σ 0.512  |  Mean min sep expected 0.575  |  Mean min sep end 0.562  |  Loss 0.062  |  Grad 1.066
Epoch 4  |  σ 0.502  |  Mean min sep expected 0.563  |  Mean min sep end 0.553  |  Loss 0.053  |  Grad 0.435
Epoch 5  |  σ 0.497  |  Mean min sep expected 0.558  |  Mean min sep end 0.552  |  Loss 0.052  |  Grad 0.398
Epoch 6  |  σ 0.493  |  Mean min sep expected 0.554  |  Mean min sep end 0.551  |  Loss 0.051  |  Grad 0.318
Epoch 7  |  σ 0.49  |  Mean min sep expected 0.55  |  Mean min sep end 0.536  |  Loss 0.036  |  Grad 1.291
Epoch 8  |  σ 0.477  |  Mean min sep expected 0.536  |  Mean min sep end 0.533  |  Loss 0.033  |  Grad 0.257
Epoch 9  |  σ 0.475  |  Mean min sep expected 0.533  |  Mean min sep end 0.53  |  Loss 0.03  |  Grad 0.539
Epoch 10  |  σ 0.469  |  Mean min sep expected 0.527  |  Mean min sep end 0.535  |  Loss 0.035  |  Grad 1.253
Epoch 11  |  σ 0.457  |  Mean min sep expected 0.513  |  Mean min sep end 0.504  |  Loss 0.004  |  Grad 1.453
Epoch 12  |  σ 0.442  |  Mean min sep expected 0.496  |  Mean min sep end 0.491  |  Loss 0.009  |  Grad -1.07
Epoch 13  |  σ 0.453  |  Mean min sep expected 0.508  |  Mean min sep end 0.504  |  Loss 0.004  |  Grad 1.599
Epoch 14  |  σ 0.437  |  Mean min sep expected 0.49  |  Mean min sep end 0.494  |  Loss 0.006  |  Grad -0.181
Epoch 15  |  σ 0.439  |  Mean min sep expected 0.493  |  Mean min sep end 0.49  |  Loss 0.01  |  Grad -1.355</code></pre><p>The final value we get is 0.439, close to the theoretical value of 0.445 if all atoms have a neighbor at the minimum pairwise energy distance. The RDF looks as follows, with the purple line corresponding to the desired distance to the closest neighbor. <img src="../images/rdf_lj.png" alt="LJ RDF"/></p><p>To make this run on the GPU the appropriate objects should be transferred to the GPU with <code>CuArray</code>: <code>coords</code>, <code>velocities</code>, <code>atoms</code> and the <code>eligible</code> matrix for the neighbor finder. If using custom interactions or some built-in interactions you may need to define methods of <code>zero</code> and <code>+</code> for your interaction type.</p><p>It is common to require a loss function formed from values throughout a simulation. In this case it is recommended to split up the simulation into a set of short simulations in the loss function, each starting from the previous final coordinates and velocities. This runs an identical simulation but makes the intermediate coordinates and velocities available for use in calculating the final loss. For example, the RMSD could be calculated from the coordinates every 100 steps and added to a variable that is then divided by the number of chunks to get a loss value corresponding to the mean RMSD over the simulation.</p><h2 id="Specific-interactions"><a class="docs-heading-anchor" href="#Specific-interactions">Specific interactions</a><a id="Specific-interactions-1"></a><a class="docs-heading-anchor-permalink" href="#Specific-interactions" title="Permalink"></a></h2><p>Next we look at obtaining gradients through simulations with specific interactions, e.g. bonds or angles between specified atoms. We will simulate two triatomic molecules and search for a minimum energy bond angle that gives a desired distance between the atoms at the end of the simulation.</p><pre><code class="language-julia hljs">using Molly, Enzyme, LinearAlgebra

dist_true = 1.0
n_steps = 150
atom_mass = 10.0
boundary = CubicBoundary(3.0)
temp = 0.05
coords = [
    SVector(0.8, 0.75, 1.5), SVector(1.5, 0.70, 1.5), SVector(2.3, 0.75, 1.5),
    SVector(0.8, 2.25, 1.5), SVector(1.5, 2.20, 1.5), SVector(2.3, 2.25, 1.5),
]
n_atoms = length(coords)
velocities = zero(coords)
atoms = [Atom(i, 1, atom_mass, 0.0, 0.0, 0.0) for i in 1:n_atoms]
simulator = VelocityVerlet(
    dt=0.05,
    coupling=BerendsenThermostat(temp, 0.5),
)
bonds = InteractionList2Atoms(
    [1, 2, 4, 5],
    [2, 3, 5, 6],
    [HarmonicBond(100.0, 0.7) for _ in 1:4],
)

function loss(θ, coords, velocities, atoms, bonds, boundary, simulator, n_steps,
              n_atoms, atom_mass, dist_true)
    angles = InteractionList3Atoms(
        [1, 4],
        [2, 5],
        [3, 6],
        [HarmonicAngle(10.0, θ), HarmonicAngle(10.0, θ)],
    )

    sys = System(
        atoms=atoms,
        coords=coords,
        boundary=boundary,
        velocities=velocities,
        specific_inter_lists=(bonds, angles),
        force_units=NoUnits,
        energy_units=NoUnits,
    )

    simulate!(sys, simulator, n_steps)

    d1 = norm(vector(sys.coords[1], sys.coords[3], boundary))
    d2 = norm(vector(sys.coords[4], sys.coords[6], boundary))
    dist_end = 0.5 * (d1 + d2)
    loss_val = abs(dist_end - dist_true)

    print(
        &quot;θ &quot;, round(rad2deg(θ); digits=1), &quot;°  |  Final dist &quot;, round(dist_end; digits=2),
        &quot;  |  Loss &quot;, round(loss_val; digits=3), &quot;  |  &quot;,
    )

    return loss_val
end

const_args = [
    Const(atoms), Const(bonds), Const(boundary), Const(simulator),
    Const(n_steps), Const(n_atoms), Const(atom_mass), Const(dist_true),
]

function train()
    θlearn = deg2rad(110.0)
    n_epochs = 20

    for epoch_n in 1:n_epochs
        print(&quot;Epoch &quot;, epoch_n, &quot;  |  &quot;)
        grad = autodiff(
            set_runtime_activity(Reverse), loss, Active, Active(θlearn),
            Duplicated(copy(coords), zero(coords)), Duplicated(copy(velocities), zero(velocities)),
            const_args...,
        )[1][1]
        println(&quot;Grad &quot;, round(grad; digits=2))
        θlearn -= grad * 0.1
    end
end

train()</code></pre><pre><code class="nohighlight hljs">Epoch 1  |  θ 110.0°  |  Final dist 1.16  |  Loss 0.155  |  Grad 0.41
Epoch 2  |  θ 107.7°  |  Final dist 1.14  |  Loss 0.138  |  Grad 0.43
Epoch 3  |  θ 105.2°  |  Final dist 1.12  |  Loss 0.119  |  Grad 0.45
Epoch 4  |  θ 102.6°  |  Final dist 1.1  |  Loss 0.099  |  Grad 0.47
Epoch 5  |  θ 100.0°  |  Final dist 1.08  |  Loss 0.077  |  Grad 0.49
Epoch 6  |  θ 97.2°  |  Final dist 1.05  |  Loss 0.049  |  Grad 0.71
Epoch 7  |  θ 93.1°  |  Final dist 1.01  |  Loss 0.012  |  Grad 0.52
Epoch 8  |  θ 90.1°  |  Final dist 0.98  |  Loss 0.015  |  Grad -0.54
Epoch 9  |  θ 93.2°  |  Final dist 1.01  |  Loss 0.013  |  Grad 0.52
Epoch 10  |  θ 90.2°  |  Final dist 0.99  |  Loss 0.015  |  Grad -0.54
Epoch 11  |  θ 93.3°  |  Final dist 1.01  |  Loss 0.014  |  Grad 0.52
Epoch 12  |  θ 90.3°  |  Final dist 0.99  |  Loss 0.014  |  Grad -0.54
Epoch 13  |  θ 93.4°  |  Final dist 1.01  |  Loss 0.015  |  Grad 0.52
Epoch 14  |  θ 90.4°  |  Final dist 0.99  |  Loss 0.013  |  Grad -0.54
Epoch 15  |  θ 93.5°  |  Final dist 1.02  |  Loss 0.016  |  Grad 0.52
Epoch 16  |  θ 90.5°  |  Final dist 0.99  |  Loss 0.012  |  Grad -0.54
Epoch 17  |  θ 93.6°  |  Final dist 1.02  |  Loss 0.016  |  Grad 0.52
Epoch 18  |  θ 90.6°  |  Final dist 0.99  |  Loss 0.011  |  Grad -0.53
Epoch 19  |  θ 93.7°  |  Final dist 1.02  |  Loss 0.017  |  Grad 0.52
Epoch 20  |  θ 90.7°  |  Final dist 0.99  |  Loss 0.01  |  Grad -0.53</code></pre><p>The final value we get is 90.7°, close to the theoretical value of 91.2° which can be calculated with trigonometry. The final simulation looks like this: <img src="../images/sim_angle.gif" alt="Angle simulation"/> In the presence of other forces this value would not be so trivially obtainable. We can record the gradients for different values of <code>θ</code>:</p><pre><code class="language-julia hljs">θs = collect(0:3:180)[2:end]
grads = [autodiff(
            set_runtime_activity(Reverse), loss, Active, Active(deg2rad(θ)),
            Duplicated(copy(coords), zero(coords)), Duplicated(copy(velocities), zero(velocities)),
            const_args...,
        )[1][1] for θ in θs]</code></pre><p>The plot of these shows that the gradient has the expected sign either side of the correct value: <img src="../images/grad_angle.png" alt="Angle gradient"/></p><h2 id="Neural-network-potentials"><a class="docs-heading-anchor" href="#Neural-network-potentials">Neural network potentials</a><a id="Neural-network-potentials-1"></a><a class="docs-heading-anchor-permalink" href="#Neural-network-potentials" title="Permalink"></a></h2><p><a href="https://fluxml.ai">Flux</a> models can also be incorporated into simulations. Here we show a neural network in the force function, though they can also be used in other parts of the simulation. This example also shows how gradients for multiple parameters can be obtained, in this case the parameters of the neural network. The jump from single to multiple parameters is important because single parameters can be optimised using finite differencing, whereas differentiable simulation is well-placed to optimise many parameters simultaneously.</p><p>We set up three pseudo-atoms and train a network to imitate the Julia logo by moving the bottom two atoms:</p><pre><code class="language-julia hljs">using Molly
using Enzyme
using Flux
import AtomsCalculators
import GLMakie
using LinearAlgebra

model = Chain(
    Dense(1, 5, relu),
    Dense(5, 1, tanh),
)

struct NNBonds{T}
    model::T
end

function AtomsCalculators.forces(sys, inter::NNBonds; kwargs...)
    vec_ij = vector(sys.coords[1], sys.coords[3], sys.boundary)
    dist = norm(vec_ij)
    f = inter.model([dist])[1] * normalize(vec_ij)
    fs = [f, zero(f), -f]
    return fs
end

dist_true = 1.0f0
n_steps = 400
boundary = CubicBoundary(5.0f0)
temp = 0.01f0
coords = [
    SVector(2.3f0, 2.07f0, 0.0f0),
    SVector(2.5f0, 2.93f0, 0.0f0),
    SVector(2.7f0, 2.07f0, 0.0f0),
]
n_atoms = length(coords)
velocities = zero(coords)
atoms = [Atom(i, 1, 10.0f0, 0.0f0, 0.0f0, 0.0f0) for i in 1:n_atoms]
simulator = VelocityVerlet(
    dt=0.02f0,
    coupling=BerendsenThermostat(temp, 0.5f0),
)

function loss(model, coords, velocities, atoms, boundary, simulator, n_steps, dist_true)
    loggers = (coords=CoordinatesLogger(Float32, 10),)
    general_inters = (NNBonds(model),)

    sys = System(
        atoms=atoms,
        coords=coords,
        boundary=boundary,
        velocities=velocities,
        general_inters=general_inters,
        loggers=loggers,
        force_units=NoUnits,
        energy_units=NoUnits,
    )

    simulate!(sys, simulator, n_steps)

    dist_end = (norm(vector(sys.coords[1], sys.coords[2], boundary)) +
                norm(vector(sys.coords[2], sys.coords[3], boundary)) +
                norm(vector(sys.coords[3], sys.coords[1], boundary))) / 3
    loss_val = abs(dist_end - dist_true)

    println(&quot;Dist end &quot;, round(dist_end; digits=3), &quot;  |  Loss &quot;, round(loss_val; digits=3))
    visualize(sys.loggers.coords, boundary, &quot;sim.mp4&quot;; show_boundary=false)

    return loss_val
end</code></pre><p>Before training the result looks like this: <img src="../images/logo_before.gif" alt="Logo before"/></p><pre><code class="language-julia hljs">function train()
    model = Chain(
        Dense(1, 5, relu),
        Dense(5, 1, tanh),
    )
    opt = Optimisers.setup(ADAM(0.02, (0.9, 0.999)), model)
    n_epochs = 20

    for epoch_n in 1:n_epochs
        print(&quot;Epoch &quot;, epoch_n, &quot;  |  &quot;)
        d_model = Flux.fmap(model) do x
            x isa Array ? zero(x) : x
        end
        autodiff(
            set_runtime_activity(Reverse), loss, Active, Duplicated(model, d_model),
            Duplicated(copy(coords), zero(coords)), Duplicated(copy(velocities), zero(velocities)),
            Const(atoms), Const(boundary), Const(simulator), Const(n_steps), Const(dist_true),
        )
        opt, model = Optimisers.update!(opt, model, d_model)
    end
end

train()</code></pre><pre><code class="nohighlight hljs">Epoch 1  |  Dist end 0.821  |  Loss 0.179
Epoch 2  |  Dist end 0.859  |  Loss 0.141
Epoch 3  |  Dist end 0.902  |  Loss 0.098
Epoch 4  |  Dist end 0.948  |  Loss 0.052
Epoch 5  |  Dist end 0.996  |  Loss 0.004
Epoch 6  |  Dist end 1.044  |  Loss 0.044
Epoch 7  |  Dist end 1.069  |  Loss 0.069
Epoch 8  |  Dist end 1.08  |  Loss 0.08
Epoch 9  |  Dist end 1.081  |  Loss 0.081
Epoch 10  |  Dist end 1.073  |  Loss 0.073
Epoch 11  |  Dist end 1.06  |  Loss 0.06
Epoch 12  |  Dist end 1.042  |  Loss 0.042
Epoch 13  |  Dist end 1.019  |  Loss 0.019
Epoch 14  |  Dist end 0.994  |  Loss 0.006
Epoch 15  |  Dist end 0.978  |  Loss 0.022
Epoch 16  |  Dist end 0.97  |  Loss 0.03
Epoch 17  |  Dist end 0.968  |  Loss 0.032
Epoch 18  |  Dist end 0.973  |  Loss 0.027
Epoch 19  |  Dist end 0.982  |  Loss 0.018
Epoch 20  |  Dist end 0.995  |  Loss 0.005</code></pre><p>After training it looks much better: <img src="../images/logo_after.gif" alt="Logo after"/> You could replace the simple network here with a much more complicated model and it would theoretically be able to train, even if it might prove practically difficult (see discussion below).</p><h2 id="Biomolecular-force-fields"><a class="docs-heading-anchor" href="#Biomolecular-force-fields">Biomolecular force fields</a><a id="Biomolecular-force-fields-1"></a><a class="docs-heading-anchor-permalink" href="#Biomolecular-force-fields" title="Permalink"></a></h2><p>Molly was used to train the <a href="https://doi.org/10.1039/D3SC05230C">GB99dms force field</a> for implicit solvent molecular dynamics of proteins. This involved doing differentiable simulations of one million steps with a loss function based on the residue-residue distance match to explicit solvent simulations. The <a href="https://github.com/greener-group/GB99dms">code is available</a>.</p><h2 id="Reversible-simulation"><a class="docs-heading-anchor" href="#Reversible-simulation">Reversible simulation</a><a id="Reversible-simulation-1"></a><a class="docs-heading-anchor-permalink" href="#Reversible-simulation" title="Permalink"></a></h2><p>Molly.jl was also used to code <a href="https://arxiv.org/abs/2412.04374">reversible simulation</a>, an extension of differentiable simulation with RAD where the gradients are calculated explicitly. This means the memory cost is constant in step number.</p><h2 id="Molecular-loss-functions"><a class="docs-heading-anchor" href="#Molecular-loss-functions">Molecular loss functions</a><a id="Molecular-loss-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Molecular-loss-functions" title="Permalink"></a></h2><p>Ultimately, you need some objective function in order to calculate the gradient for each parameter. Here are some ideas for loss functions suitable for differentiable molecular simulations:</p><ul><li>The distance between atoms at the end of the simulation compared to some reference state. This loss is used in the examples given here, is physically reasonable, and has obvious bounds.</li><li>The distance between atoms throughout the simulation.</li><li>The radial distribution function of atoms.</li><li>RMSD between atoms and a reference state - this would be suitable for macromolecules.</li><li>dRMSD, the distance between a distance map and a reference distance map.</li><li>The radius of gyration of a molecule.</li><li>The flexibility of a set of atoms over the simulation.</li><li>Supramolecular geometry, for example assembly of molecules into straight fibres.</li><li>The correlation of different velocities over the simulation.</li><li>The energy of the system.</li><li>The temperature of the system.</li><li>Some measure of phase change or a critical point.</li><li>A combination of the above, for example to obtain a force field relevant to both ordered and disordered proteins.</li></ul><p>Some of these are currently not possible in Molly as the loggers are ignored for gradient purposes, but this will hopefully change in future.</p><h2 id="Tips-and-tricks"><a class="docs-heading-anchor" href="#Tips-and-tricks">Tips and tricks</a><a id="Tips-and-tricks-1"></a><a class="docs-heading-anchor-permalink" href="#Tips-and-tricks" title="Permalink"></a></h2><ul><li>The magnitude of gradients may be less important than the sign. Consider sampling gradients across different sources of stochasticity, such as starting velocities and conformations.</li><li>Exploding gradients prove a problem when using the velocity Verlet integrator in the NVE ensemble. This is why the velocity rescaling and Berendsen thermostats were used in the above examples. Langevin dynamics also seems to work. It is likely that the development of suitable simulation strategies and thermostats will be necessary to unlock the potential of differentiable simulation.</li><li>Forward mode AD holds much promise for differentiable simulation, provided that the number of parameters is small, because the memory requirement is constant in the number of simulation steps. However, if the code runs slower than non-differentiable alternatives then the best approach is likely to use finite differencing with the simulation as a black box. Adjoint sensitivity is another approach to getting gradients which is not yet available in Molly.jl.</li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../documentation/">« Documentation</a><a class="docs-footer-nextpage" href="../examples/">Examples »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Thursday 6 February 2025 16:26">Thursday 6 February 2025</span>. Using Julia version 1.11.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
